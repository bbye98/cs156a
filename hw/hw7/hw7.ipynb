{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benjamin Ye  \n",
    "CS/CNE/EE 156a: Learning Systems (Fall 2023)  \n",
    "November 13, 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "import requests\n",
    "from sklearn import svm\n",
    "\n",
    "CWD = globals()['_dh'][0].resolve()\n",
    "sys.path.insert(0, str(CWD.parent))\n",
    "from cs156a import (\n",
    "    linear_regression, validate_binary, target_function_random_line, \n",
    "    generate_data, perceptron, support_vector_machine\n",
    ")\n",
    "\n",
    "DATA_DIR = (CWD / \"../data\").resolve()\n",
    "\n",
    "rng = np.random.default_rng()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems 1–5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_DIR.mkdir(exist_ok=True)\n",
    "raw_data = {}\n",
    "for prefix in [\"in\", \"out\"]:\n",
    "    if not (DATA_DIR / f\"{prefix}.dta\").exists():\n",
    "        r = requests.get(f\"http://work.caltech.edu/data/{prefix}.dta\")\n",
    "        with open(DATA_DIR / f\"{prefix}.dta\", \"wb\") as f:\n",
    "            f.write(r.content)\n",
    "    raw_data[prefix] = np.loadtxt(DATA_DIR / f\"{prefix}.dta\")\n",
    "\n",
    "print(\"\\n[HW7 P1–5]\")\n",
    "ns = (25, len(raw_data[\"in\"]) - 25)\n",
    "data = np.array_split(raw_data[\"in\"], (ns[0],))\n",
    "transform_funcs = (\n",
    "    lambda x: np.ones((len(x), 1), dtype=float), \n",
    "    lambda x: x,\n",
    "    lambda x: x[:, :1] ** 2, \n",
    "    lambda x: x[:, 1:] ** 2, \n",
    "    lambda x: np.prod(x, axis=1, keepdims=True), \n",
    "    lambda x: np.abs(x[:, :1] - x[:, 1:]), \n",
    "    lambda x: np.abs(x[:, :1] + x[:, 1:])\n",
    ")\n",
    "for i in range(2):\n",
    "    print(f\"Linear regression statistics for {ns[i]}:{ns[1 - i]} split:\")\n",
    "    for k in np.arange(3, 8):\n",
    "        w, E_in, E_out = linear_regression(\n",
    "            vf=validate_binary, \n",
    "            x=data[i][:, :-1],\n",
    "            y=data[i][:, -1],\n",
    "            transform=lambda x: np.hstack(\n",
    "                tuple(f(x) for f in transform_funcs[:k])\n",
    "            ),\n",
    "            x_test=raw_data[\"out\"][:, :-1], \n",
    "            y_test=raw_data[\"out\"][:, -1], \n",
    "            x_validate=data[1 - i][:, :-1],\n",
    "            y_validate=data[1 - i][:, -1],\n",
    "            hyp=True,\n",
    "            rng=rng\n",
    "        )\n",
    "        print(f\"  {k=}, E_in_test={E_in[0]:.3f}, \"\n",
    "              f\"E_in_validate={E_in[1]:.3f}, {E_out=:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = rng.uniform(size=(10_000_000, 2))\n",
    "e_1, e_2 = x.mean(axis=0)\n",
    "e = x.min(axis=1).mean()\n",
    "print(\"\\n[HW7 P6]\\nExpected values for continuous uniform distribution:\",\n",
    "      f\"  {e_1=:.3f}, {e_2=:.3f}, {e=:.3f}\", sep=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problems 8–10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Ns = [10, 100]\n",
    "N_runs = 1_000\n",
    "N_test = 100_000\n",
    "\n",
    "print(f\"\\n[HW7 P8–10]\\nPLA vs. SVM with hard margins over {N_runs:,} runs:\")\n",
    "f = target_function_random_line(rng=rng)\n",
    "clf = svm.SVC(C=np.finfo(float).max, kernel=\"linear\")\n",
    "for N in Ns:\n",
    "    prob_svm = 0\n",
    "    N_sv_avg = 0\n",
    "    for _ in range(N_runs):\n",
    "        while True:\n",
    "            x, y = generate_data(N, f, bias=True, rng=rng)\n",
    "            if not np.allclose(y, y[0]):\n",
    "                break\n",
    "        x_test, y_test = generate_data(N_test, f, bias=True, rng=rng)\n",
    "        _, E_out_pla = perceptron(N, f, vf=validate_binary, x=x, y=y, \n",
    "                                  x_test=x_test, y_test=y_test, rng=rng)\n",
    "        N_sv, E_out_svm = support_vector_machine(\n",
    "            N, f, vf=validate_binary, x=x, y=y, x_test=x_test, y_test=y_test,\n",
    "            clf=clf, rng=rng\n",
    "        )\n",
    "        prob_svm += E_out_svm < E_out_pla\n",
    "        N_sv_avg += N_sv\n",
    "    prob_svm /= N_runs\n",
    "    N_sv_avg /= N_runs\n",
    "    print(f\"  {N=}, {prob_svm=:.3f}, {N_sv_avg=:.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
