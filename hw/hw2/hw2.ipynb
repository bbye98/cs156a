{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Benjamin Ye  \n",
    "CS/CNE/EE 156a: Learning Systems (Fall 2023)  \n",
    "October 9, 2023"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "sys.path.insert(0, str(globals()['_dh'][0].resolve().parent))\n",
    "from cs156a import (coin_flip, hoeffding_inequality, \n",
    "                    target_function_random_line, perceptron, linear_regression,\n",
    "                    target_function_hw2, generate_data, validate_binary)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems 1–2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW2 P1–2]\n",
      "Coin flip statistics over 100,000 trials:\n",
      "  first: nu=0.50022\n",
      "  random: nu=0.49990\n",
      "  minimum: nu=0.03773\n",
      "\n",
      "Hoeffding's inequality:\n",
      "   eps |  bound  |      first      |      random     |     minimum    \n",
      "  -----+---------+-----------------+-----------------+-----------------\n",
      "   0.0 | 2.00000 | 0.24503 (True)  | 0.24671 (True)  | 0.00000 (True) \n",
      "   0.1 | 1.63746 | 0.40849 (True)  | 0.41019 (True)  | 0.00000 (True) \n",
      "   0.2 | 0.89866 | 0.23619 (True)  | 0.23471 (True)  | 0.00000 (True) \n",
      "   0.3 | 0.33060 | 0.08894 (True)  | 0.08714 (True)  | 0.00002 (True) \n",
      "   0.4 | 0.08152 | 0.01934 (True)  | 0.01900 (True)  | 0.37724 (False)\n",
      "   0.5 | 0.01348 | 0.00201 (True)  | 0.00225 (True)  | 0.62274 (False)\n"
     ]
    }
   ],
   "source": [
    "rng = np.random.default_rng()\n",
    "n_trials = 100_000\n",
    "n_flips = 10\n",
    "labels = (\"first\", \"random\", \"minimum\")\n",
    "print(f\"\\n[HW2 P1–2]\\nCoin flip statistics over {n_trials:,} trials:\")\n",
    "nus = coin_flip(n_trials, rng=rng)\n",
    "for label, nu in zip(labels, nus.mean(axis=1)):\n",
    "    print(f\"  {label}: {nu=:.5f}\")\n",
    "\n",
    "print(\"\\nHoeffding's inequality:\")\n",
    "epss = np.linspace(0, 0.5, 6)\n",
    "hist = np.apply_along_axis(\n",
    "    lambda x: np.histogram(x, bins=np.linspace(-0.05, 1.05, 12))[0], 1, nus\n",
    ") # requires at least 8 GB RAM\n",
    "probs = np.hstack((hist[:, (5,)], hist[:, 4::-1] + hist[:, 6:])) / n_trials\n",
    "bounds = hoeffding_inequality(n_flips, epss)\n",
    "print(\"   eps |  bound  | \", \" | \".join(l.center(15) for l in labels),\n",
    "      \"\\n  -----+---------+\", \"+\".join(3 * [17 * \"-\"]), sep=\"\")\n",
    "for eps, bound, prob, satisfy in zip(\n",
    "        epss, bounds, probs.T, (probs <= bounds).T):\n",
    "    print(\n",
    "        f\"   {eps:.1f} | {bound:.5f} |\",\n",
    "        \" | \".join(\n",
    "            f\"{p:.5f} ({s})\".ljust(15) for p, s in zip(prob, satisfy)\n",
    "        )\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems 5–7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW2 P5–7]\n",
      "Linear regression statistics over 1,000 runs:\n",
      "  N=100, E_in=0.041, E_out=0.049\n",
      "\n",
      "PLA (with linear regression hypothesis) statistics over 1,000 runs:\n",
      "  N=10, iters=4\n"
     ]
    }
   ],
   "source": [
    "N = 100\n",
    "n_runs = 1_000\n",
    "print(f\"\\n[HW2 P5–7]\\nLinear regression statistics over {n_runs:,} runs:\")\n",
    "E_in, E_out = np.mean(\n",
    "    [linear_regression(N, target_function_random_line(rng=rng), \n",
    "                       validate_binary, rng=rng)\n",
    "     for _ in range(n_runs)], \n",
    "    axis=0\n",
    ")\n",
    "print(f\"  {N=:,}, {E_in=:.3f}, {E_out=:.3f}\")\n",
    "\n",
    "N = 10\n",
    "print(\"\\nPLA (with linear regression hypothesis) statistics over\",\n",
    "      f\"{n_runs:,} runs:\")\n",
    "iters = np.empty(n_runs, dtype=float)\n",
    "for i in range(n_runs):\n",
    "    f = target_function_random_line(rng=rng)\n",
    "    x, y = generate_data(N, f, bias=True, rng=rng)\n",
    "    iters[i] = perceptron(\n",
    "        N, f, validate_binary, x=x, y=y, rng=rng,\n",
    "        w=linear_regression(N, f, validate_binary, x=x, y=y, rng=rng, \n",
    "                            hyp=True)[0]\n",
    "    )[0]\n",
    "print(f\"  {N=:,}, iters={iters.mean():,.0f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Problems 8–10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "[HW2 P8–10]\n",
      "Linear regression (with linear feature vector) statistics over 1,000 runs:\n",
      "  N=1,000, noise=0.100, E_in=0.504\n",
      "\n",
      "Linear regression (with nonlinear feature vector) hypothesis over 1,000 runs:\n",
      "  w=[-0.99449, -0.00138, 0.00158, 0.00036, 1.55987, 1.56042]\n",
      "  [a] g=[-1, -0.05, 0.08, 0.13, 1.5, 1.5] (prob=0.97216)\n",
      "  [b] g=[-1, -0.05, 0.08, 0.13, 1.5, 15] (prob=0.66315)\n",
      "  [c] g=[-1, -0.05, 0.08, 0.13, 15, 1.5] (prob=0.66256)\n",
      "  [d] g=[-1, -1.5, 0.08, 0.13, 0.05, 0.05] (prob=0.63276)\n",
      "  [e] g=[-1, -0.05, 0.08, 1.5, 0.15, 0.15] (prob=0.56092)\n",
      "  N=1,000, noise=0.100, E_out=0.123\n"
     ]
    }
   ],
   "source": [
    "f = target_function_hw2()\n",
    "N = N_test = n_runs = 1_000\n",
    "noise = (0.1, lambda y: -y)\n",
    "print(\"\\n[HW2 P8–10]\\nLinear regression (with linear feature vector)\",\n",
    "      f\"statistics over {n_runs:,} runs:\")\n",
    "E_in = np.mean(\n",
    "    [linear_regression(N, f, validate_binary, noise=noise, rng=rng)[0]\n",
    "     for _ in range(n_runs)]\n",
    ")\n",
    "print(f\"  {N=:,}, noise={noise[0]:.3f}, {E_in=:.3f}\")\n",
    "\n",
    "transform = lambda x: np.hstack((\n",
    "    x, \n",
    "    x[:, 1:2] * x[:, 2:], \n",
    "    x[:, 1:2] ** 2,\n",
    "    x[:, 2:] ** 2\n",
    "))\n",
    "gs = np.array(((-1, -0.05, 0.08, 0.13, 1.5, 1.5), \n",
    "               (-1, -0.05, 0.08, 0.13, 1.5, 15),\n",
    "               (-1, -0.05, 0.08, 0.13, 15, 1.5),\n",
    "               (-1, -1.5, 0.08, 0.13, 0.05, 0.05),\n",
    "               (-1, -0.05, 0.08, 1.5, 0.15, 0.15)))\n",
    "print(\"\\nLinear regression (with nonlinear feature vector) hypothesis\",\n",
    "      f\"over {n_runs:,} runs:\")\n",
    "w = np.mean(\n",
    "    [linear_regression(N, f, validate_binary, transform=transform, \n",
    "                       noise=noise, rng=rng, hyp=True)[0]\n",
    "     for _ in range(n_runs)],\n",
    "    axis=0\n",
    ")\n",
    "print(\"  w=[\", \", \".join(f\"{v:.5f}\" for v in w), \"]\", sep=\"\")\n",
    "probs = np.zeros((N_test, 5))\n",
    "Es_out = np.zeros(N_test)\n",
    "for i in range(n_runs):\n",
    "    x_test, y_test = generate_data(N_test, f, bias=True, rng=rng)\n",
    "    x_test = transform(x_test)\n",
    "    y_test[rng.choice(N_test, round(noise[0] * N_test), False)] *= -1\n",
    "    h_test = np.sign(x_test @ w)\n",
    "    probs[i] = validate_binary(gs.T, x_test, h_test[:, None])\n",
    "    Es_out[i] = np.count_nonzero(h_test != y_test) / N_test\n",
    "for i, (g, p) in enumerate(zip(gs, probs.mean(axis=0))):\n",
    "    print(f\"  [{chr(97 + i)}] g=[\", \", \".join(f\"{v:.2g}\" for v in g),\n",
    "          f\"] (prob={1 - p:.5f})\", sep=\"\")\n",
    "print(f\"  {N=:,}, noise={noise[0]:.3f}, E_out={Es_out.mean():.3f}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cs156a",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
